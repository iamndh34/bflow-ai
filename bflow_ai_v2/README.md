# BFlow AI V2 - COA Agent

Version 2 Ä‘Æ¡n giáº£n hÃ³a: **Chá»‰ COA Agent - Tra cá»©u tÃ i khoáº£n káº¿ toÃ¡n**

## ğŸ¯ TÃ­nh nÄƒng

- **Tra cá»©u tÃ i khoáº£n**: TK 156 lÃ  gÃ¬?
- **Tra cá»©u theo loáº¡i**: TÃ i sáº£n ngáº¯n háº¡n cÃ³ nhá»¯ng TK nÃ o?
- **So sÃ¡nh TT99 vs TT200**: TK 111 trong TT99 khÃ¡c TT200 tháº¿ nÃ o?
- **Tra cá»©u theo tá»« khÃ³a**: TÃ i khoáº£n vá» hÃ ng hÃ³a
- **Ollama Local LLM**: KhÃ´ng cáº§n API key
- **Streaming Response**: Real-time streaming

## ğŸ“‹ YÃªu cáº§u

- Python 3.10+
- Ollama Ä‘ang cháº¡y
- Model: `gemma3:4b`

## ğŸš€ CÃ i Ä‘áº·t

```bash
cd bflow_ai_v2

# Install dependencies
pip install -r requirements.txt

# Pull model
ollama pull gemma3:4b

# Run server
python -m app.main
```

## ğŸ“– API Endpoints

### COA Query

```
GET /api/coa/ask
```

Query Parameters:
- `question`: CÃ¢u há»i (required)

Examples:

```bash
# Tra cá»©u tÃ i khoáº£n
curl "http://localhost:8010/api/coa/ask?question=TK+156+lÃ +gÃ¬?"

# So sÃ¡nh
curl "http://localhost:8010/api/coa/ask?question=So+sÃ¡nh+TK+111+giá»¯a+TT99+vÃ +TT200"

# Tra cá»©u theo tá»« khÃ³a
curl "http://localhost:8010/api/coa/ask?question=TÃ i+khoáº£n+vá»+hÃ ng+hÃ³a"
```

### Health Check

```
GET /api/coa/health
```

Docs: `http://localhost:8010/api/docs`

## ğŸ“ Cáº¥u trÃºc

```
bflow_ai_v2/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base.py          # Base agent
â”‚   â”‚   â””â”€â”€ coa_agent.py     # COA specialist
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ endpoints.py      # COA API endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py        # Configuration
â”‚   â”‚   â””â”€â”€ ollama_client.py # Ollama client
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ coa_index.py      # COA data indexing
â”‚   â””â”€â”€ main.py              # Application
â”œâ”€â”€ data/
â”‚   â””â”€â”€ coa/
â”‚       â”œâ”€â”€ coa_99.json
â”‚       â”œâ”€â”€ coa_200.json
â”‚       â””â”€â”€ coa_compare_99_vs_200.json
â””â”€â”€ requirements.txt
```

## ğŸ§ª Testing

```bash
# Test health
curl http://localhost:8010/api/coa/health

# Test query
curl "http://localhost:8010/api/coa/ask?question=TK+111+lÃ +gÃ¬?"
```

## âš™ï¸ Configuration

Copy `.env.example` to `.env`:

```bash
cp .env.example .env
```

Edit `.env`:
```
HOST=0.0.0.0
PORT=8010
OLLAMA_BASE_URL=http://localhost:11434
GENERATION_MODEL=gemma3:4b
```
