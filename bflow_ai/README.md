# BFLOW AI - Multi-Module AI Assistant

Unified Multi-Module AI Assistant vá»›i Pipeline Architecture, há»— trá»£ má»Ÿ rá»™ng nhiá»u chuyÃªn domains (Accounting, HR, CRM, Sales, etc.)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Request Flow](#request-flow)
- [API Endpoints](#api-endpoints)
- [Configuration](#configuration)
- [Installation](#installation)
- [Usage](#usage)
- [Development](#development)
- [Optimizations](#optimizations)

---

## ğŸ¯ Overview

**BFLOW AI** lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vá»›i kiáº¿n trÃºc pipeline-based, há»— trá»£:

- âœ… **Multi-Module Routing**: Tá»± Ä‘á»™ng phÃ¢n loáº¡i cÃ¢u há»i Ä‘áº¿n module phÃ¹ há»£p
- âœ… **Hybrid Semantic Caching**: Káº¿t há»£p similarity search + exact match cache
- âœ… **Redis-Backed Cache**: Persistent cache vá»›i in-memory fallback
- âœ… **Multi-Agent System**: Má»—i module cÃ³ cÃ¡c agents chuyÃªn biá»‡t
- âœ… **Streaming Response**: Character-by-character streaming cho natural feel
- âœ… **Session Management**: File-based session vá»›i semantic history matching

### Current Modules

| Module | Description | Agents |
|--------|-------------|---------|
| **ACCOUNTING** | Káº¿ toÃ¡n, tÃ i khoáº£n, háº¡ch toÃ¡n | COA, POSTING_ENGINE, GENERAL_ACCOUNTING |
| **GENERAL** | CÃ¢u há»i chung, xÃ£ giao | GENERAL_FREE |

---

## ğŸ—ï¸ Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     UI / Client                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Unified Entry Point                            â”‚
â”‚         GET /api/ai-bflow/ask                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Module Router (SLM + Keywords)                 â”‚
â”‚   PhÃ¢n loáº¡i: ACCOUNTING / GENERAL / HR / CRM / ...         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼             â–¼             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚Accountingâ”‚  â”‚   HR    â”‚   â”‚   CRM   â”‚  ...
        â”‚ Pipeline â”‚  â”‚ Pipeline â”‚  â”‚ Pipeline â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚             â”‚             â”‚
             â–¼             â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       Processing Pipeline (8 Steps)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Multi-Agent Execution          â”‚
    â”‚  COA / POSTING_ENGINE / GENERAL       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       Ollama LLM (qwen2.5:3b)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Hybrid Cache System                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚   â”‚ Semantic       â”‚    â”‚  Streaming     â”‚                 â”‚
â”‚   â”‚ History Cache  â”‚    â”‚  Cache (Exact) â”‚                 â”‚
â”‚   â”‚ (Similarity)   â”‚    â”‚  (Redis+Memory)â”‚                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Pipeline (8 Steps)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Session Management                                  â”‚
â”‚ - Táº¡o session má»›i náº¿u chÆ°a cÃ³                                â”‚
â”‚ - Get session history                                       â”‚
â”‚ - Format messages cho LLM                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Context Builder                                     â”‚
â”‚ - Parse request parameters                                  â”‚
â”‚ - Build AgentContext object                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Agent Router                                        â”‚
â”‚ - Fast rule-based routing (O(1))                            â”‚
â”‚ - SLM classification vá»›i few-shot learning                  â”‚
â”‚ - Semantic fallback vá»›i embeddings                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Semantic History Check                              â”‚
â”‚ - Search trong session history báº±ng hybrid similarity       â”‚
â”‚   * Sentence similarity (70%)                               â”‚
â”‚   * Keyword similarity (30%)                                â”‚
â”‚ - Threshold: 0.85                                           â”‚
â”‚ - Return cached response náº¿u match                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ (miss)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Streaming Cache Check                               â”‚
â”‚ - Exact match cache vá»›i MD5 hash key                        â”‚
â”‚ - Redis-backed vá»›i in-memory fallback                       â”‚
â”‚ - TTL: 3600s (1 hour)                                       â”‚
â”‚ - Return cached response náº¿u match                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ (miss)
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Agent Execution (LLM Call)                          â”‚
â”‚ - Extract keywords tá»« cÃ¢u há»i                              â”‚
â”‚ - Search data (COA, Posting Engine)                         â”‚
â”‚ - Build context tá»« data                                     â”‚
â”‚ - Build prompt cho LLM                                      â”‚
â”‚ - Call Ollama streaming                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 7: Stream Processing                                   â”‚
â”‚ - Buffer streaming chunks                                   â”‚
â”‚ - Optimize buffer size (5 words/buffer)                     â”‚
â”‚ - Yield mÆ°á»£t mÃ  cho frontend                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 8: Response Saver                                      â”‚
â”‚ - Accumulate full response                                  â”‚
â”‚ - Save to Streaming Cache (Redis)                           â”‚
â”‚ - Save to Session History (file-based)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Tech Stack

### Core Framework
- **FastAPI** - Async web framework vá»›i auto OpenAPI docs
- **Python 3.11+** - Primary language
- **Pydantic** - Data validation vÃ  settings management

### AI/ML
- **Ollama** - Local LLM serving
  - `qwen2.5:3b` - Generation model (quantized q4_0)
  - `qwen2.5:0.5b` - Classification model (SLM)
- **Sentence-Transformers** - Embeddings cho semantic search
  - `dangvantuan/vietnamese-embedding` - Vietnamese embeddings

### Cache & Storage
- **Redis** - Persistent cache backend
  - Streaming cache
  - LLM response cache
  - Session storage (optional)
- **In-Memory Fallback** - Python dict vá»›i LRU eviction
- **File-based Storage** - Session history (JSON files)

### Data Processing
- **NumPy** - Vectorized similarity computation
- **Hashlib** - MD5 cache key generation

---

## ğŸ“ Project Structure

```
bflow_ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # FastAPI application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                          # API Endpoints
â”‚   â”‚   â””â”€â”€ endpoints/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ ask.py               # Unified endpoint
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                         # Core Services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # Embedding model with cache
â”‚   â”‚   â”œâ”€â”€ ollama_client.py         # LLM client pool
â”‚   â”‚   â””â”€â”€ redis_client.py          # Cache client wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                     # Pipeline Architecture
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ask.py                   # Processing Pipeline (8 steps)
â”‚   â”‚   â””â”€â”€ router.py                # Module Router
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                       # Multi-Agent System
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                  # Base agent classes
â”‚   â”‚   â”œâ”€â”€ orchestrator.py          # Agent orchestration
â”‚   â”‚   â””â”€â”€ [module]_agents.py       # Domain-specific agents
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                     # Business Services
â”‚   â”‚   â”œâ”€â”€ [module]_index.py        # Data lookup indexes
â”‚   â”‚   â”œâ”€â”€ similarity.py            # Similarity computation
â”‚   â”‚   â”œâ”€â”€ history_search.py        # History search
â”‚   â”‚   â”œâ”€â”€ session_manager.py       # Session management
â”‚   â”‚   â”œâ”€â”€ [cache]_service.py       # Cache services
â”‚   â”‚   â””â”€â”€ data/                    # RAG Data files
â”‚   â”‚
â”‚   â””â”€â”€ [other]/                      # Other modules
â”‚
â”œâ”€â”€ .env                             # Environment configuration (private)
â”œâ”€â”€ main.py                          # Application entry point
â”œâ”€â”€ docker-compose.yaml              # Docker services (optional)
â””â”€â”€ requirements.txt                 # Python dependencies
```

---

## ğŸ”„ Request Flow

### Complete Flow Example

```
User: "TK 156 lÃ  gÃ¬?"
   â”‚
   â–¼
UI: GET /api/ai-bflow/ask?question=TK+156+lÃ +gÃ¬?
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Module Router Classify                                   â”‚
â”‚    - Keywords: "TK", "156" â†’ ACCOUNTING module             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Accounting Pipeline â†’ Session Manager                    â”‚
â”‚    - Create/Get session: sess_abc123                        â”‚
â”‚    - Get history (last 10 messages)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Context Builder                                          â”‚
â”‚    - Build AgentContext with question, history, etc.       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Agent Router                                             â”‚
â”‚    - Fast rule: Has "156" â†’ COA agent                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Semantic History Check                                  â”‚
â”‚    - Search history with similarity                         â”‚
â”‚    - Not found â†’ Continue                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Streaming Cache Check                                   â”‚
â”‚    - MD5 hash lookup in Redis                               â”‚
â”‚    - Not found â†’ Continue                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. COA Agent Execution                                     â”‚
â”‚    - Extract keywords: ["156"]                             â”‚
â”‚    - COA Index lookup: "156" â†’ "HÃ ng hÃ³a"                   â”‚
â”‚    - Build prompt with COA context                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Call Ollama LLM                                          â”‚
â”‚    - Model: qwen2.5:3b-q4_0                                â”‚
â”‚    - Stream response character-by-character                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. Stream Processing                                        â”‚
â”‚    - Buffer chunks (5 words)                                â”‚
â”‚    - Yield to frontend                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. Save Response                                           â”‚
â”‚     - Save to Redis Streaming Cache (key: md5)             â”‚
â”‚     - Save to Session History (JSON file)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
UI: Stream response to user
```

---

## ğŸŒ API Endpoints

### Unified Endpoint

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/ai-bflow/ask` | **Unified entry point** - Auto route to appropriate module |

#### Request Parameters

```
GET /api/ai-bflow/ask
```

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `question` | string | âœ… | - | CÃ¢u há»i |
| `session_id` | string | âŒ | null | Session ID (auto-create if null) |
| `chat_type` | string | âŒ | thinking | Chat mode: `thinking` or `free` |
| `item_group` | string | âŒ | GOODS | Item group (for posting engine) |
| `partner_group` | string | âŒ | CUSTOMER | Partner group (for posting engine) |
| `turn_off_routing` | bool | âŒ | false | Dev: Skip routing |
| `turn_off_history` | bool | âŒ | false | Dev: Skip history check |
| `turn_off_cache` | bool | âŒ | false | Dev: Skip cache check |
| `turn_off_llm` | bool | âŒ | false | Dev: Mock LLM response |

#### Response Format

```
__SESSION_ID__:sess_abc123
TK 156 lÃ  tÃ i khoáº£n HÃ ng hÃ³a...
[streaming character by character]
```

### Info Endpoint

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | API information & available endpoints |

---

## âš™ï¸ Configuration

### Environment Variables (.env)

```bash
# =============================================================================
# Service Configuration
# =============================================================================
OLLAMA_HOST=<ollama_host>
REDIS_HOST=<redis_host>
REDIS_PORT=<redis_port>
REDIS_DB=<redis_db>
REDIS_PASSWORD=<redis_password>  # Optional

# =============================================================================
# Model Configuration
# =============================================================================
CLASSIFIER_MODEL=<model_name>
GENERATION_MODEL=<model_name>

# =============================================================================
# Cache Configuration
# =============================================================================
ENABLE_LLM_CACHE=true
CACHE_TTL=3600
MAX_CACHE_SIZE=100
CACHE_SIMULATE_DELAY=0.02
CACHE_CHARS_PER_CHUNK=1

# =============================================================================
# Semantic History Configuration
# =============================================================================
ENABLE_SEMANTIC_HISTORY=true
SEMANTIC_MODE=hybrid
SEMANTIC_ALPHA=0.7
SEMANTIC_SIMILARITY_THRESHOLD=0.85
```

> **Note**: Xem `.env.example` Ä‘á»ƒ cÃ³ template Ä‘áº§y Ä‘á»§.

### Key Settings Explained

| Setting | Description | Recommended Values |
|---------|-------------|-------------------|
| `SEMANTIC_MODE` | Similarity algorithm | `hybrid` (best), `sentence`, `keyword` |
| `SEMANTIC_ALPHA` | Sentence vs keyword weight | `0.7` (70% sentence), `0.5` (balanced), `0.3` (keyword-focused) |
| `SEMANTIC_SIMILARITY_THRESHOLD` | Match threshold | `0.90` (strict), `0.85` (default), `0.80` (loose) |
| `CACHE_SIMULATE_DELAY` | Cached response typing speed | `0.02` (smooth), `0.01` (fast), `0.03` (slow) |
| `CACHE_CHARS_PER_CHUNK` | Characters per chunk from cache | `1` (char-by-char), `3-5` (phrase-by-phrase) |

---

## ğŸš€ Installation

### Prerequisites

- Python 3.11+
- Ollama (with qwen2.5 models)
- Redis (optional, recommended for production)
- 8GB RAM minimum (16GB recommended)

### Step 1: Clone Repository

```bash
git clone <repository-url>
cd bflow_ai
```

### Step 2: Install Python Dependencies

```bash
pip install -r requirements.txt
```

### Step 3: Install Ollama

```bash
# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Pull models (xem .env Ä‘á»ƒ biáº¿t model cá»¥ thá»ƒ)
ollama pull <model_name>
```

### Step 4: Install Redis (Optional but Recommended)

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install redis-server
sudo systemctl start redis

# macOS
brew install redis
brew services start redis

# Or use Docker
docker run -d -p <redis_port>:6379 redis:alpine
```

### Step 5: Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit configuration
nano .env  # hoáº·c vi .env
```

### Step 6: Run Application

```bash
# Development
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Production
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Step 7: Verify Installation

```bash
# Check API
curl <your_api_base_url>/

# Check OpenAPI docs
open <your_api_base_url>/docs

# Test query
curl "<your_api_base_url>/api/ai-bflow/ask?question=Your+question"
```

---

## ğŸ“– Usage

### Basic Usage

```python
import requests

# Simple question
API_BASE = "<your_api_base_url>"  # e.g., "https://api.yourdomain.com"
response = requests.get(
    f"{API_BASE}/api/ai-bflow/ask",
    params={"question": "Your question here"}
)

# Stream response
for line in response.iter_lines():
    print(line.decode('utf-8'), end='', flush=True)
```

### With Session

```python
import requests

API_BASE = "<your_api_base_url>"

# First question - creates session
response1 = requests.get(
    f"{API_BASE}/api/ai-bflow/ask",
    params={"question": "First question"}
)
session_id = response1.text.split('\n')[0].split(':')[1]

# Follow-up question - uses session
response2 = requests.get(
    f"{API_BASE}/api/ai-bflow/ask",
    params={
        "question": "Follow-up question",
        "session_id": session_id
    }
)
```

### Free Mode (No routing)

```python
response = requests.get(
    "<your_api_base_url>/api/ai-bflow/ask",
    params={
        "question": "Hello, how are you?",
        "chat_type": "free"
    }
)
```

---

## ğŸ› ï¸ Development

### Adding New Module

1. **Create Pipeline Class**

```python
# app/pipeline/hr_pipeline.py
class HRPipeline:
    def __init__(self):
        self.session_step = SessionManagerStep()
        # ... other steps

    def process(self, question, session_id, **kwargs):
        # Implementation
        pass
```

2. **Register in Module Router**

```python
# app/pipeline/router.py
AVAILABLE_MODULES = {
    "ACCOUNTING": {...},
    "HR": {
        "name": "NhÃ¢n sá»±",
        "description": "CÃ¢u há»i vá» lÆ°Æ¡ng, tuyá»ƒn dá»¥ng...",
        "keywords": ["lÆ°Æ¡ng", "tuyá»ƒn dá»¥ng", "nhÃ¢n viÃªn"],
        "pipeline_class": HRPipeline
    }
}
```

### Adding New Agent

```python
# app/agents/new_agent.py
class NewAgent(BaseAgent):
    name = "NEW_AGENT"
    description = "Agent description"

    def stream_execute(self, context: AgentContext):
        # Implementation
        yield response
```

### Cache Management

```python
from app.services.streaming_cache import clear_streaming_cache
from app.services.llm_service import get_llm_service

# Clear streaming cache
clear_streaming_cache()

# Clear LLM cache
llm_service = get_llm_service()
llm_service.clear_cache()

# Get cache statistics
stats = llm_service.get_stats()
print(f"Hit rate: {stats['hit_rate']:.2%}")
```

---

## âš¡ Optimizations

### Performance Optimizations Applied

1. **Connection Pooling** - Singleton Ollama client (~50ms saved per request)
2. **Single Embedding Model** - LRU cache for embeddings (~2s startup saved)
3. **COA Indexing** - O(1) lookup instead of O(n) search
4. **Optimized Streaming** - 5-word buffer reduces yield calls by ~90%
5. **Redis Cache** - Persistent cache with ~1ms latency
6. **Hybrid Similarity** - Vectorized NumPy operations
7. **Batch Operations** - Encode multiple texts at once

### Cache Hierarchy

```
Request â†’ Semantic History (50-150ms)
         â†’ Streaming Cache (1ms)
         â†’ LLM Cache (1ms)
         â†’ LLM Call (500-2000ms)
```

### Performance Tips

1. **Enable Redis** for production - 10-100x faster than file I/O
2. **Use appropriate thresholds** - Higher threshold = fewer false positives
3. **Tune buffer sizes** - 5 words is optimal for Vietnamese
4. **Monitor cache hit rates** - Target >70% hit rate

---

## ğŸ“Š Monitoring

### Cache Statistics

```python
from app.services.llm_service import get_llm_service

stats = get_llm_service().get_stats()
# {
#     "cache_backend": "Redis",
#     "total_requests": 1000,
#     "cache_hits": 750,
#     "cache_misses": 250,
#     "hit_rate": 0.75
# }
```

### Redis Statistics

```python
from app.core.redis_client import RedisClient

stats = RedisClient.get_stats()
# {
#     "available": true,
#     "connected_clients": 2,
#     "used_memory_human": "45.2M",
#     "total_keys": 1523
# }
```

---

## ğŸ”’ Security Considerations

1. **API Rate Limiting** - Implement rate limiting for production
2. **Input Validation** - Sanitize user inputs
3. **Redis Authentication** - Use `REDIS_PASSWORD` in production
4. **CORS Configuration** - Restrict `allow_origins` in production
5. **Session Management** - Implement session expiration

---

## ğŸ› Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| Redis connection refused | Check if Redis is running: `sudo systemctl status redis` |
| Ollama not responding | Check Ollama: `ollama list` |
| Import errors | Run: `pip install -r requirements.txt` |
| Slow responses | Check if cache is enabled in `.env` |
| Out of memory | Reduce `MAX_CACHE_SIZE` or use Redis |

---

## ğŸ“ License

[Your License Here]

---

## ğŸ‘¥ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## ğŸ“ Contact

[Your Contact Information]

---

**Last Updated**: 2026-02-04
**Version**: 1.0.0
