# BFLOW AI - Trá»£ LÃ½ AI Äa Chá»©c NÄƒng

Trá»£ lÃ½ AI thÃ´ng minh vá»›i kiáº¿n trÃºc Pipeline-based, há»— trá»£ má»Ÿ rá»™ng nhiá»u chuyÃªn ngÃ nh.

## ğŸ¯ Tá»•ng Quan

**BFLOW AI** lÃ  trá»£ lÃ½ AI thÃ´ng minh vá»›i kiáº¿n trÃºc pipeline-based:

- âœ… **Multi-Module Routing**: Tá»± Ä‘á»™ng phÃ¢n loáº¡i cÃ¢u há»i
- âœ… **Hybrid Caching**: Káº¿t há»£p semantic search + exact match cache
- âœ… **Redis-Backed Cache**: Persistent cache vá»›i in-memory fallback
- âœ… **Multi-Agent System**: CÃ¡c agents chuyÃªn biá»‡t cho tá»«ng domain
- âœ… **Streaming Response**: Character-by-character streaming mÆ°á»£t mÃ 
- âœ… **Session Management**: Quáº£n lÃ½ lá»‹ch sá»­ vá»›i semantic history matching

### Modules Hiá»‡n CÃ³

| Module | MÃ´ táº£ | Agents |
|--------|-------|---------|
| **ACCOUNTING** | Káº¿ toÃ¡n, tÃ i khoáº£n, háº¡ch toÃ¡n | COA, POSTING_ENGINE, GENERAL_ACCOUNTING |
| **GENERAL** | CÃ¢u há»i chung, xÃ£ giao | GENERAL_FREE |

---

## ğŸ—ï¸ Kiáº¿n TrÃºc

```
UI Client â†’ GET /api/ai-bflow/ask
                â†“
        Module Router (SLM + Keywords)
                â†“
    Accounting Pipeline (8 Steps):
        1. Session Management
        2. Context Builder
        3. Agent Router
        4. Streaming Cache Check
        5. Agent Execution (LLM)
        6. Stream Processing
        7. Response Saver
                â†“
        Multi-Agent Execution (COA, POSTING_ENGINE, GENERAL)
                â†“
        Ollama LLM (qwen2.5:7b)
                â†“
        Hybrid Cache (Redis + Memory)
                â†“
        Stream Response to User
```

---

## ğŸ”§ Tech Stack

**Core:**
- FastAPI, Python 3.11+, Pydantic

**AI/ML:**
- Ollama (qwen2.5:7b, qwen2.5:0.5b)
- Sentence-Transformers (Vietnamese embeddings)

**Cache/Storage:**
- Redis, In-Memory Fallback, File-based Session History

---

## ğŸ“ Cáº¥u TrÃºc Project

```
bflow_ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                      # FastAPI entry point
â”‚   â”œâ”€â”€ api/                          # API endpoints
â”‚   â”œâ”€â”€ core/                         # Config, embeddings, Ollama client
â”‚   â”œâ”€â”€ pipeline/                     # Processing pipeline (8 steps)
â”‚   â”œâ”€â”€ agents/                       # Multi-agent system
â”‚   â”‚   â”œâ”€â”€ templates/                 # Response templates
â”‚   â””â”€â”€ services/                     # Business services
â”œâ”€â”€ .env                             # Environment config
â”œâ”€â”€ main.py                          # App entry point
â””â”€â”€ requirements.txt                 # Python dependencies
```

---

## ğŸŒ API Endpoints

### Unified Endpoint

**`GET /api/ai-bflow/ask`**

| Parameter | Type | Required | Default |
|-----------|------|----------|---------|
| `question` | string | âœ… | - |
| `session_id` | string | âŒ | null |
| `chat_type` | string | âŒ | thinking |
| `item_group` | string | âŒ | GOODS |
|`partner_group` | string | âŒ | CUSTOMER |

---

## âš™ï¸ Cáº¥u HÃ¬nh

### Environment Variables (.env)

```bash
# Service
OLLAMA_HOST=http://localhost:11434
REDIS_HOST=localhost
REDIS_PORT=6379

# Models
CLASSIFIER_MODEL=qwen2.5:0.5b
GENERATION_MODEL=qwen2.5:7b

# Cache
ENABLE_LLM_CACHE=true
CACHE_TTL=3600
MAX_CACHE_SIZE=100

# Semantic History
ENABLE_SEMANTIC_HISTORY=true
SEMANTIC_SIMILARITY_THRESHOLD=0.85
```

---

## ğŸš€ CÃ i Äáº·t

```bash
# Install dependencies
pip install -r requirements.txt

# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama pull qwen2.5:7b

# Run server
uvicorn main:app --port 8010
```

---

## ğŸ“– Sá»­ Dá»¥

```python
import requests

API_BASE = "http://localhost:8010"

response = requests.get(
    f"{API_BASE}/api/ai-bflow/ask",
    params={"question": "TK 111 lÃ  gÃ¬?"}
)

for line in response.iter_lines():
    print(line.decode('utf-8'), end='', flush=True)
```

---

## ğŸ› Troubleshooting

| Váº¥n Ä‘á» | Giáº£i phÃ¡p |
|--------|----------|
| Redis connection refused | `sudo systemctl status redis` |
| Ollama not responding | `ollama list` |
| Slow responses | Báº­t cache trong `.env` |
| Out of memory | Giáº£m `MAX_CACHE_SIZE` |

---

**Xem thÃªm hÆ°á»›ng dáº«n phÃ¡t triá»ƒn vÃ  má»Ÿ rá»™ng:** [README_DEV.md](README_DEV.md)

---

**Version:** 1.0.0
**Last Updated:** 2026-02-05
